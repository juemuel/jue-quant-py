import sys
import os

from pkg_resources import non_empty_lines
sys.path.append(os.path.join(os.path.dirname(__file__), '../../..'))

from app.services.data_service import get_stock_history
from app.services.indicator_service import IndicatorCalculator
from app.services.strategy_service import generate_ma_crossover_signal_from_indicators, generate_rsi_signal_from_indicators
from app.services.strategy_service import generate_unified_signals
from app.services.event_service import MarketEvent, EventType, EventSeverity
from datetime import datetime as dt
import datetime  # ä¿®æ”¹è¿™è¡Œï¼šå¯¼å…¥å®Œæ•´çš„datetimeæ¨¡å—
import pandas as pd
from core.logger import logger
# æ·»åŠ Excelå¯¼å‡ºåŠŸèƒ½
import openpyxl
# =========== å…¬ç”¨æ–¹æ³• ===========
def get_and_preprocess_stock_data(source="akshare", code="000001", market="SH", 
                                 start_date="20240801", end_date="20241201", page_size=1000):
    """
    è·å–å¹¶é¢„å¤„ç†è‚¡ç¥¨æ•°æ®çš„é€šç”¨æ–¹æ³•
    è¿”å›: (success: bool, df: DataFrame, message: str)
    """
    # 1. è·å–è‚¡ç¥¨å†å²æ•°æ®
    result = get_stock_history(
        source=source, code=code, market=market,
        start_date=start_date, end_date=end_date, page_size=page_size
    )
    
    if result.get('status') != 'success':
        return False, None, f"æ•°æ®è·å–å¤±è´¥: {result.get('message')}"
    
    # 2. æå–æ•°æ®å¹¶è½¬æ¢ä¸ºDataFrame
    data_info = result.get('data', {})
    data_list = data_info.get('list', [])
    
    if not data_list:
        return False, None, "æ²¡æœ‰è·å–åˆ°å®é™…æ•°æ®"
    
    df = pd.DataFrame(data_list)
    
    # 3. æ£€æŸ¥å¿…è¦åˆ—
    required_columns = ['æ”¶ç›˜ä»·', 'æ—¥æœŸ']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        return False, None, f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}"
    
    # 4. æ•°æ®é¢„å¤„ç†
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
    df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
    df['æ”¶ç›˜ä»·'] = pd.to_numeric(df['æ”¶ç›˜ä»·'], errors='coerce')
    
    # åˆ é™¤æ— æ•ˆæ•°æ®
    nan_count = df['æ”¶ç›˜ä»·'].isna().sum()
    if nan_count > 0:
        df = df.dropna(subset=['æ”¶ç›˜ä»·'])
    
    # ä¸ºanalytic_serviceå‡†å¤‡æ•°æ®
    df['æ”¶ç›˜'] = df['æ”¶ç›˜ä»·']
    
    return True, df, f"æˆåŠŸè·å–å¹¶é¢„å¤„ç† {len(df)} è¡Œæ•°æ®"
def ensure_numeric_columns(df, columns):
    """
    ç¡®ä¿æŒ‡å®šåˆ—ä¸ºæ•°å€¼ç±»å‹çš„é€šç”¨æ–¹æ³•
    """
    df_copy = df.copy()
    for col in columns:
        if col in df_copy.columns:
            df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')
    return df_copy
def analyze_basic_signals(signal_df, signal_name="ä¿¡å·", display_columns=None):
    """
    åˆ†æå’Œæ˜¾ç¤ºä¿¡å·ç»Ÿè®¡çš„é€šç”¨æ–¹æ³•
    """
    if 'signal' not in signal_df.columns:
        return f"é”™è¯¯ï¼š{signal_name}æ•°æ®ä¸­æ²¡æœ‰signalåˆ—"
    
    # ç¡®ä¿signalåˆ—ä¸ºæ•°å€¼ç±»å‹
    df_copy = signal_df.copy()
    df_copy['signal'] = pd.to_numeric(df_copy['signal'], errors='coerce').fillna(0)
    
    # ç»Ÿè®¡ä¿¡å·
    buy_signals = df_copy[df_copy['signal'] == 1]
    sell_signals = df_copy[df_copy['signal'] == -1]
    non_zero_signals = df_copy[df_copy['signal'] != 0]

    result = f"\n=== {signal_name}ç»Ÿè®¡åˆ†æ ===\n"
    result += f"ä¹°å…¥ä¿¡å·æ•°é‡: {len(buy_signals)}\n"
    result += f"å–å‡ºä¿¡å·æ•°é‡: {len(sell_signals)}\n"
    
    if len(non_zero_signals) > 0:
        result += f"\næ‰€æœ‰{signal_name}éé›¶ä¿¡å· ({len(non_zero_signals)}ä¸ª)ï¼Œå‰10å¦‚ä¸‹ï¼š\n"
        if display_columns:
            available_cols = [col for col in display_columns if col in df_copy.columns]
            result += non_zero_signals[available_cols].head(10).to_string()
        else:
            result += non_zero_signals.head(10).to_string()
    else:
        result += f"\næ²¡æœ‰ç”Ÿæˆä»»ä½•{signal_name}"
    
    return result
def calculate_and_validate_indicator(df, calculator_method, indicator_name, **kwargs):
    """
    è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¹¶éªŒè¯ç»“æœçš„é€šç”¨æ–¹æ³•
    ä½¿ç”¨æ–°çš„ IndicatorCalculator
    """
    try:
        # åˆ›å»ºè®¡ç®—å™¨å®ä¾‹
        calculator = IndicatorCalculator()
        
        # è°ƒç”¨è®¡ç®—å™¨æ–¹æ³•
        result = calculator_method(calculator, df, **kwargs)
        
        if result.get('status') != 'success':
            return False, None, f"{indicator_name}è®¡ç®—å¤±è´¥: {result.get('message')}"
        
        data_list = result.get('data', [])
        if not data_list:
            return False, None, f"{indicator_name}è®¡ç®—è¿”å›ç©ºæ•°æ®"
        
        indicator_df = pd.DataFrame(data_list)
        return True, indicator_df, f"{indicator_name}è®¡ç®—æˆåŠŸ"
        
    except Exception as e:
        return False, None, f"{indicator_name}è®¡ç®—å¼‚å¸¸: {str(e)}"
def analyze_unified_signals(unified_result):
    """
    åˆ†æç»Ÿä¸€ä¿¡å·ç”Ÿæˆç»“æœ
    """
    if unified_result['status'] != 'success':
        return f"âŒ ç»Ÿä¸€ä¿¡å·ç”Ÿæˆå¤±è´¥: {unified_result.get('message')}"
    
    data = unified_result['data']
    unified_signals = data['unified_signals']
    
    result = "\n=== ç»Ÿä¸€ä¿¡å·ç”Ÿæˆåˆ†æ ===\n"
    result += f"âœ“ æ•°æ®é©±åŠ¨ä¿¡å·æ•°é‡: {data['data_signals_count']}\n"
    result += f"âœ“ äº‹ä»¶é©±åŠ¨ä¿¡å·æ•°é‡: {data['event_signals_count']}\n"
    result += f"âœ“ ç»Ÿä¸€åæ€»ä¿¡å·æ•°é‡: {data['total_signals']}\n"
    
    # åˆ†æä¿¡å·ç±»å‹åˆ†å¸ƒ
    if unified_signals:
        signal_types = {}
        signal_strengths = []
        
        for signal in unified_signals:
            signal_type = signal.get('type', 'unknown')
            signal_types[signal_type] = signal_types.get(signal_type, 0) + 1
            
            strength = signal.get('strength', 0)
            if strength > 0:
                signal_strengths.append(strength)
        
        result += "\nç»Ÿä¸€åçš„ä¿¡å·ç±»å‹åˆ†å¸ƒ:\n"
        for sig_type, count in signal_types.items():
            result += f"  - {sig_type}: {count}ä¸ª\n"
        
        if signal_strengths:
            avg_strength = sum(signal_strengths) / len(signal_strengths)
            result += f"\nå¹³å‡ä¿¡å·å¼ºåº¦: {avg_strength:.3f}\n"
            result += f"æœ€å¼ºä¿¡å·å¼ºåº¦: {max(signal_strengths):.3f}\n"
            result += f"æœ€å¼±ä¿¡å·å¼ºåº¦: {min(signal_strengths):.3f}\n"
        
        # æ˜¾ç¤ºå‰5ä¸ªä¿¡å·è¯¦æƒ…
        result += "\nå‰10ä¸ªç»Ÿä¸€ä¿¡å·è¯¦æƒ…:\n"
        for i, signal in enumerate(unified_signals[:10]):
            signal_type = signal.get('signal_type', 'unknown')
            direction = signal.get('direction', 0)
            reason = signal.get('reason', signal.get('metadata', {}).get('reason', 'N/A'))
            result += f"  {i+1}. ç±»å‹: {signal_type}({direction}), "
            result += f"å¼ºåº¦: {signal.get('strength', 0):.3f}, "
            result += f"æ—¶é—´: {signal.get('timestamp', 'N/A')}\n"
            result += f"     åŸå› : {reason}\n"
    
    return result
def create_mock_events_data(df=None, event_count=20):
    """
    åˆ›å»ºæ¨¡æ‹Ÿäº‹ä»¶æ•°æ®ç”¨äºæµ‹è¯•
    
    Args:
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ "YYYYMMDD"
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ "YYYYMMDD"
        event_count: è¦ç”Ÿæˆçš„äº‹ä»¶æ•°é‡
    """
    import random
    
    if df is None or df.empty:
        # å¦‚æœæ²¡æœ‰æä¾›DataFrameï¼Œä½¿ç”¨é»˜è®¤æ—¥æœŸèŒƒå›´
        start_dt = datetime.datetime(2024, 1, 1)
        end_dt = datetime.datetime(2024, 12, 1)
    else:
        # ä»DataFrameä¸­æå–æ—¥æœŸèŒƒå›´
        if 'æ—¥æœŸ' in df.columns:
            dates = pd.to_datetime(df['æ—¥æœŸ'])
            start_dt = dates.min().to_pydatetime()
            end_dt = dates.max().to_pydatetime()
        else:
            # å¦‚æœæ²¡æœ‰æ—¥æœŸåˆ—ï¼Œä½¿ç”¨é»˜è®¤èŒƒå›´
            start_dt = datetime.datetime(2024, 1, 1)
            end_dt = datetime.datetime(2024, 12, 1)
    
    # è®¡ç®—æ—¥æœŸèŒƒå›´
    date_range = (end_dt - start_dt).days
    if date_range <= 0:
        date_range = 365  # é»˜è®¤ä¸€å¹´èŒƒå›´
    
    mock_events = []
    
    # å®šä¹‰äº‹ä»¶æ¨¡æ¿
    # ä¿®æ”¹äº‹ä»¶æ¨¡æ¿ï¼Œå¢åŠ æ›´å¤šæ ·åŒ–çš„æ•°æ®
    event_templates = [
        {
            "type": EventType.NEWS,
            "titles": ["é‡å¤§åˆä½œåè®®ç­¾ç½²", "æ–°äº§å“å‘å¸ƒä¼šæˆåŠŸä¸¾åŠ", "ä¸šç»©å¤§å¹…å¢é•¿", "è·å¾—é‡è¦å¥–é¡¹"],
            "sentiment_range": (0.6, 0.9),  # æé«˜æ­£é¢æƒ…æ„ŸèŒƒå›´
            "severity": EventSeverity.HIGH   # æé«˜ä¸¥é‡ç¨‹åº¦
        },
        {
            "type": EventType.NEWS,
            "titles": ["ç›‘ç®¡è°ƒæŸ¥å¯åŠ¨", "é‡å¤§è¿è§„äº‹ä»¶", "ä¸šç»©å¤§å¹…ä¸‹æ»‘", "é«˜ç®¡ç¦»èŒé£æ³¢"],
            "sentiment_range": (-0.9, -0.6),  # æé«˜è´Ÿé¢æƒ…æ„ŸèŒƒå›´
            "severity": EventSeverity.HIGH     # æé«˜ä¸¥é‡ç¨‹åº¦
        },
        {
            "type": EventType.EARNINGS,
            "titles": ["å³å°†å‘å¸ƒå­£åº¦è´¢æŠ¥", "å¹´åº¦ä¸šç»©é¢„å‘Š", "ä¸­æœŸä¸šç»©è¯´æ˜ä¼š", "æŠ•èµ„è€…å…³ç³»æ´»åŠ¨"],
            "sentiment_range": (-0.3, 0.7),   # æ‰©å¤§æƒ…æ„ŸèŒƒå›´
            "severity": EventSeverity.MEDIUM
        }
    ]
    
    # ç”ŸæˆæŒ‡å®šæ•°é‡çš„äº‹ä»¶
    for i in range(event_count):
        # éšæœºé€‰æ‹©äº‹ä»¶æ¨¡æ¿
        template = random.choice(event_templates)
        
        # éšæœºç”Ÿæˆæ—¥æœŸ
        random_days = random.randint(0, date_range)
        event_date = start_dt + datetime.timedelta(days=random_days)
        
        # éšæœºé€‰æ‹©æ ‡é¢˜å’Œæƒ…æ„Ÿåˆ†æ•°
        title = random.choice(template["titles"])
        sentiment_min, sentiment_max = template["sentiment_range"]
        sentiment_score = random.uniform(sentiment_min, sentiment_max)
        
        # åˆ›å»ºäº‹ä»¶
        event = MarketEvent(
            event_id=f"event_{i+1:03d}",
            event_type=template["type"],
            symbol="000001",
            timestamp=event_date,
            title=title,
            content=f"{title}çš„è¯¦ç»†å†…å®¹æè¿°",
            severity=template["severity"],
            sentiment_score=sentiment_score,
            keywords=title.split(),
            source="æ¨¡æ‹Ÿæ•°æ®æº",
            metadata={"event_index": i+1, "template_type": template["type"].value}
        )
        
        mock_events.append(event)
    
    # æŒ‰æ—¶é—´æ’åº
    mock_events.sort(key=lambda x: x.timestamp)
    
    return mock_events
# ============ åŸºç¡€å•ä¿¡å·ç”Ÿæˆ(ä½¿ç”¨strategy_serviceä¸­çš„å•ä¸€ä¿¡å·çš„ç”Ÿæˆå‡½æ•°) ============
# MAä½¿ç”¨ç®€å•çš„é‡‘å‰æ­»å‰åˆ¤æ–­,å›ºå®šä½¿ç”¨MA5å’ŒMA20
# RSIå›ºå®šé˜ˆå€¼è¶…å–30,è¶…ä¹°70,è§¦åŠå°±ç”Ÿæˆ
def debug_basic_strategy_flow():

    """
    ä½¿ç”¨å°è£…æ–¹æ³•çš„ç®€åŒ–ç‰ˆåŸºç¡€ç­–ç•¥æµç¨‹è°ƒè¯•
    """
    print("=== å¼€å§‹è°ƒè¯•åŸºç¡€ç­–ç•¥æµç¨‹ï¼ˆç®€åŒ–ç‰ˆï¼‰===")
    
    try:
        # 1. è·å–å’Œé¢„å¤„ç†æ•°æ®
        success, df, message = get_and_preprocess_stock_data()
        if not success:
            print(f"æ•°æ®å‡†å¤‡å¤±è´¥: {message}")
            return
        print(f"âœ“ {message}")
        
        # 2. è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
        success, df_with_ma, message = calculate_and_validate_indicator(
            df, IndicatorCalculator.calculate_moving_averages, "ç§»åŠ¨å¹³å‡çº¿", periods=[5, 20]
        )
        if not success:
            print(f"âœ— {message}")
            return
        print(f"âœ“ {message}")
        
        # ç¡®ä¿æ•°å€¼ç±»å‹
        # ç¡®ä¿æ•°å€¼ç±»å‹ - æ³¨æ„æ–°çš„åˆ—åæ ¼å¼æ˜¯ SMA5, SMA20
        df_with_ma = ensure_numeric_columns(df_with_ma, ['æ”¶ç›˜ä»·', 'æ”¶ç›˜', 'SMA5', 'SMA20'])
        
        # é‡å‘½ååˆ—ä»¥ä¿æŒå…¼å®¹æ€§
        if 'SMA5' in df_with_ma.columns:
            df_with_ma['MA5'] = df_with_ma['SMA5']
        if 'SMA20' in df_with_ma.columns:
            df_with_ma['MA20'] = df_with_ma['SMA20']
            
        # 3. è®¡ç®—RSI
        success, df_with_rsi, message = calculate_and_validate_indicator(
            df, IndicatorCalculator.calculate_rsi, "RSIæŒ‡æ ‡", period=14
        )
        if not success:
            print(f"âœ— {message}")
            df_with_rsi = df_with_ma  # ä½¿ç”¨MAæ•°æ®ç»§ç»­
        else:
            print(f"âœ“ {message}")
            df_with_rsi = ensure_numeric_columns(df_with_rsi, ['æ”¶ç›˜ä»·', 'æ”¶ç›˜', 'RSI'])
        
        # åˆå§‹åŒ–ä¿¡å·å˜é‡
        ma_signals_row = []
        rsi_signals_row = []
        # 4. ç”ŸæˆMAäº¤å‰ä¿¡å·
        # åœ¨ç”ŸæˆMAä¿¡å·å‰æ·»åŠ è°ƒè¯•ä¿¡æ¯
        logger.debug(f"[Service]df_with_maåˆ—: {df_with_ma.columns.tolist()}")
        logger.info(f"[DebugBasicStrategy]å¼€å§‹ç”ŸæˆMAäº¤å‰ä¿¡å·ï¼Œæ•°æ®è¡Œæ•°: {len(df_with_ma)}")
        logger.info(f"[DebugBasicStrategy]MA5é•¿åº¦: {len(df_with_ma['MA5']) if 'MA5' in df_with_ma.columns else 0}, MA20é•¿åº¦: {len(df_with_ma['MA20']) if 'MA20' in df_with_ma.columns else 0}")
        ma_signal_result = generate_ma_crossover_signal_from_indicators(df_with_ma, short_period=5, long_period=20)
        if ma_signal_result['status'] == 'success':
            ma_signals_row = ma_signal_result['data']
            signal_df = pd.DataFrame(ma_signals_row)
            print(analyze_basic_signals(signal_df, "MAäº¤å‰ä¿¡å·", ['æ—¥æœŸ', 'MA5', 'MA20', 'signal']))
        logger.info(f"[DebugBasicStrategy]MAäº¤å‰ä¿¡å·æ•°é‡ï¼ˆå«é›¶ï¼‰: {len(ma_signals_row)}")
        # 5. ç”ŸæˆRSIä¿¡å·
        # åœ¨ç”ŸæˆRSIä¿¡å·å‰æ·»åŠ è°ƒè¯•ä¿¡æ¯
        logger.info(f"[DebugBasicStrategy]df_with_rsiåˆ—: {df_with_rsi.columns.tolist()}")
        logger.info(f"[DebugBasicStrategy]å¼€å§‹ç”ŸæˆRSIä¿¡å·ï¼ŒRSIé•¿åº¦: {len(df_with_rsi['RSI14']) if 'RSI14' in df_with_rsi.columns else 0}")
        rsi_signal_result = generate_rsi_signal_from_indicators(df_with_rsi, period=14, oversold=30, overbought=70)
        if rsi_signal_result['status'] == 'success':
            rsi_signals_row = rsi_signal_result['data']
            signal_df = pd.DataFrame(rsi_signals_row)
            print(analyze_basic_signals(signal_df, "RSIä¿¡å·", ['æ—¥æœŸ', 'æ”¶ç›˜ä»·', 'RSI', 'signal']))
        # å¯¼å‡ºExcelæ–‡ä»¶ - åŸºç¡€ç­–ç•¥æµç¨‹
        try:
            timestamp = dt.now().strftime("%Y%m%d_%H%M%S")
            excel_file = f"basic_strategy_signals_{timestamp}.xlsx"
            
            with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
                # å¯¼å‡ºMAä¿¡å·
                if ma_signals_row:
                    ma_df = pd.DataFrame(ma_signals_row)
                    ma_df.to_excel(writer, sheet_name='MA_Signals', index=False)
                    print(f"âœ“ MAä¿¡å·å·²å¯¼å‡ºåˆ° {excel_file} - MA_Signals sheet")
                
                # å¯¼å‡ºRSIä¿¡å·
                if rsi_signals_row:
                    rsi_df = pd.DataFrame(rsi_signals_row)
                    rsi_df.to_excel(writer, sheet_name='RSI_Signals', index=False)
                    print(f"âœ“ RSIä¿¡å·å·²å¯¼å‡ºåˆ° {excel_file} - RSI_Signals sheet")
                
                # å¯¼å‡ºåŸå§‹æ•°æ®(æºå¸¦æŒ‡æ ‡)
                df_with_rsi.to_excel(writer, sheet_name='Raw_Data', index=False)
                print(f"âœ“ åŸå§‹æ•°æ®å·²å¯¼å‡ºåˆ° {excel_file} - Raw_Data sheet")
                
            print(f"\nğŸ“Š åŸºç¡€ç­–ç•¥ä¿¡å·å·²ä¿å­˜åˆ°: {excel_file}")
        except Exception as e:
                logger.error(f"å¯¼å‡ºExcelæ–‡ä»¶å¤±è´¥: {e}")
                print(f"âŒ Excelå¯¼å‡ºå¤±è´¥: {e}")
        print("\n=== åŸºç¡€ç­–ç•¥æµç¨‹è°ƒè¯•å®Œæˆ ===")
        # ç»Ÿè®¡éé›¶ä¿¡å· - ä¿®æ­£è¿‡æ»¤é€»è¾‘
        def is_nonzero_signal(signal_dict):
            signal_value = signal_dict.get('signal', 0)
            # å¤„ç†å„ç§å¯èƒ½çš„é›¶å€¼è¡¨ç¤º
            if signal_value is None:
                return False
            if isinstance(signal_value, str):
                try:
                    signal_value = float(signal_value)
                except (ValueError, TypeError):
                    return False
            return signal_value != 0 and signal_value != 0.0
        
        ma_nonzero = [s for s in ma_signals_row if is_nonzero_signal(s)]
        rsi_nonzero = [s for s in rsi_signals_row if is_nonzero_signal(s)]
        
        logger.info(f"[DebugBasicStrategy]MAéé›¶ä¿¡å·æ•°é‡: {len(ma_nonzero)}")
        logger.info(f"[DebugBasicStrategy]RSIéé›¶ä¿¡å·æ•°é‡: {len(rsi_nonzero)}")
        logger.info(f"[DebugBasicStrategy]æ€»éé›¶ä¿¡å·æ•°é‡: {len(ma_nonzero) + len(rsi_nonzero)}")
        
    except Exception as e:
        logger.error(f"è°ƒè¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print(f"\né”™è¯¯: {e}")

# ============ ç»Ÿä¸€ä¿¡å·ç”Ÿæˆ ============
# æ•°æ®é©±åŠ¨ä¸­ä½¿ç”¨MAå’ŒRSI,äº‹ä»¶é©±åŠ¨ä¸­ä½¿ç”¨æ–°é—»æƒ…æ„Ÿå’Œè´¢æŠ¥å‘å¸ƒ
# é»˜è®¤MAä¿¡å·ç”Ÿæˆ:MA5/MA20;
# é»˜è®¤RSIä¿¡å·ç”Ÿæˆ:å‘¨æœŸ14,è¶…ä¹°è¶…å–30/70; å¹¶ä¸”éœ€è¦æ»¡è¶³æˆäº¤é‡volume > avg_volume * 1.2
def debug_unified_signals():
    """
    è°ƒè¯•ç»Ÿä¸€ä¿¡å·ç”Ÿæˆå™¨
    """
    print("=== å¼€å§‹è°ƒè¯•ç»Ÿä¸€ä¿¡å·ç”Ÿæˆå™¨ ===")
    
    try:
        # 1. è·å–å’Œé¢„å¤„ç†æ•°æ®
        print("\n1. è·å–å’Œé¢„å¤„ç†è‚¡ç¥¨æ•°æ®...")
        success, df, message = get_and_preprocess_stock_data()
        if not success:
            print(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {message}")
            return
        print(f"âœ“ {message}")
        
        # 2. åˆ›å»ºæ¨¡æ‹Ÿäº‹ä»¶æ•°æ®
        print("\n2. åˆ›å»ºæ¨¡æ‹Ÿäº‹ä»¶æ•°æ®...")
        dates = pd.to_datetime(df['æ—¥æœŸ'])
        start_dt = dates.min().to_pydatetime()
        end_dt = dates.max().to_pydatetime()
        print(f"è‚¡ç¥¨æ•°æ®æ—¶é—´èŒƒå›´: {start_dt} ~ {end_dt}")
        events_data = create_mock_events_data(
            df,
            event_count=300
        )
        print(f"âœ“ åˆ›å»ºäº† {len(events_data)} ä¸ªæ¨¡æ‹Ÿäº‹ä»¶")
        print(f"âœ“ äº‹ä»¶æ—¶é—´èŒƒå›´: {events_data[0].timestamp.strftime('%Y-%m-%d')} åˆ° {events_data[-1].timestamp.strftime('%Y-%m-%d')}")
        # 3. é…ç½®ä¿¡å·ç”Ÿæˆå‚æ•°
        print("\n3. é…ç½®ä¿¡å·ç”Ÿæˆå‚æ•°...")
        
        # æ•°æ®é©±åŠ¨ä¿¡å·è§„åˆ™é…ç½®
        data_signal_config = {
            'ma_crossover': {
                'enable': True,
                'use_parameterized': False,  # æ”¹ä¸ºFalseï¼Œä½¿ç”¨å›ºå®šå‚æ•°ç‰ˆæœ¬ï¼Œä¸debug_basic_strategy_flowä¸€è‡´
                'short_period': 5,           # ä¸debug_basic_strategy_flowç›¸åŒ
                'long_period': 20,           # ä¸debug_basic_strategy_flowç›¸åŒ
                'adaptive': True,
                'filter_config': {
                    'volatility_filter': {'enable': False, 'min_volatility': 0.3, 'max_volatility': 1},  # ç¦ç”¨è¿‡æ»¤å™¨
                    'volume_confirmation': {'enable': False, 'volume_multiplier': 1, 'lookback_days': 20},
                    'trend_strength_filter': {'enable': False, 'min_adx': 25},
                    'signal_strength_filter': {'enable': False, 'min_strength': 0.3}
                }
            },
            'rsi': {
                'enable': True,
                'use_parameterized': False,  # æ”¹ä¸ºFalseï¼Œä½¿ç”¨å›ºå®šå‚æ•°ç‰ˆæœ¬
                'period': 14,                # ä¸debug_basic_strategy_flowç›¸åŒ
                'oversold': 30,              # ä¸debug_basic_strategy_flowç›¸åŒ
                'overbought': 70,            # ä¸debug_basic_strategy_flowç›¸åŒ
                'filter_config': {
                    'volume_confirmation': {'enable': False, 'volume_multiplier': 1, 'lookback_days': 20},  # ç¦ç”¨è¿‡æ»¤å™¨
                    'volatility_filter': {'enable': False, 'min_volatility': 0.3, 'max_volatility': 0.5},
                    'trend_strength_filter': {'enable': False, 'min_adx': 25},
                    'signal_strength_filter': {'enable': False, 'min_strength': 0.3}
                }
            }
        }
        # äº‹ä»¶é©±åŠ¨ä¿¡å·è§„åˆ™é…ç½®
        event_signal_config = {
            'news_sentiment': {
                'enable': True,
                'use_parameterized': True,  # ä½¿ç”¨å‚æ•°åŒ–ç‰ˆæœ¬
                'sentiment_threshold': 0.8,  # è‡ªå®šä¹‰é˜ˆå€¼
                'severity_levels': [EventSeverity.HIGH, EventSeverity.CRITICAL]
            },
            'earnings': {
                'enable': True,
                'use_parameterized': False  # ä½¿ç”¨å›ºå®šå‚æ•°ç‰ˆæœ¬
            },
            'keyword_trigger': {
                'enable': True,
                'use_parameterized': True,  # ä½¿ç”¨å‚æ•°åŒ–ç‰ˆæœ¬
                'positive_keywords': ['çªç ´', 'åˆ›æ–°é«˜', 'åˆ©å¥½'],
                'negative_keywords': ['æš´è·Œ', 'äºæŸ', 'é£é™©'],
                'strength': 0.7,
            }
        }
        print("âœ“ ä¿¡å·é…ç½®å®Œæˆ")
        print(f"  - æ•°æ®é©±åŠ¨ä¿¡å·: MAäº¤å‰({data_signal_config['ma_crossover']['short_period']},{data_signal_config['ma_crossover']['long_period']}), RSI({data_signal_config['rsi']['period']})")
         # å®‰å…¨åœ°è®¿é—®äº‹ä»¶ä¿¡å·é…ç½®
        news_threshold = event_signal_config.get('news_sentiment', {}).get('sentiment_threshold', 'é»˜è®¤')
        earnings_info = "å‚æ•°åŒ–" if event_signal_config.get('earnings', {}).get('use_parameterized', False) else "å›ºå®šå‚æ•°"
        keyword_strength = event_signal_config.get('keyword_trigger', {}).get('strength', 'é»˜è®¤')
        print(f"  - äº‹ä»¶é©±åŠ¨ä¿¡å·: æ–°é—»æƒ…ç»ª(é˜ˆå€¼{news_threshold}), è´¢æŠ¥é¢„æœŸ({earnings_info}), å…³é”®è¯è§¦å‘(å¼ºåº¦{keyword_strength})")

        print("\n4. ç”Ÿæˆç»Ÿä¸€ä¿¡å·...")
        # 4.1 ç”Ÿæˆç»Ÿä¸€ç»„åˆä¿¡å·
        # unified_result = generate_unified_signals(
        #     price_data=df,
        #     events_data=events_data,
        #     data_signal_config=data_signal_config,
        #     event_signal_config=event_signal_config
        # )
        # print(analyze_unified_signals(unified_result))
        # 4.2 ç”Ÿæˆä»…æ•°æ®é©±åŠ¨çš„ä¿¡å·
        data_only_result = generate_unified_signals(
            price_data=df,
            events_data=None,  # ä¸æä¾›äº‹ä»¶æ•°æ®
            data_signal_config=data_signal_config,
            event_signal_config=None
        )
        print(analyze_unified_signals(data_only_result))
        # 4.3 ç”Ÿæˆä»…äº‹ä»¶é©±åŠ¨çš„ä¿¡å·
        # event_only_result = generate_unified_signals(
        #     price_data=df,
        #     events_data=events_data,
        #     data_signal_config=None,
        #     event_signal_config=event_signal_config
        # )
        # print(analyze_unified_signals(event_only_result))
        # 4.4 ç”Ÿæˆé»˜è®¤é…ç½®çš„ä¿¡å·
        # default_result = generate_unified_signals(price_data=df, events_data=events_data)
        # print(analyze_unified_signals(default_result))
        
        # 5. åˆ†æç»“æœ
        # 5. å¯¼å‡ºåˆ°Excelæ–‡ä»¶
        print("\n5. å¯¼å‡ºæ•°æ®åˆ°Excel...")
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        excel_file = f"unified_signals_debug_{timestamp}.xlsx"
        
        try:
            with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
                # 5.1 å¯¼å‡ºè‚¡ç¥¨å†å²æ•°æ®
                print("  - å¯¼å‡ºè‚¡ç¥¨å†å²æ•°æ®...")
                df.to_excel(writer, sheet_name='è‚¡ç¥¨å†å²æ•°æ®', index=False)
                
                # 5.2 å¯¼å‡ºdata_signalsï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if 'data' in data_only_result and 'data_signals' in data_only_result['data']:
                    data_signals = data_only_result['data']['data_signals']
                    if data_signals:
                        print(f"  - å¯¼å‡ºæ•°æ®ä¿¡å· ({len(data_signals)}æ¡)...")
                        if isinstance(data_signals, list) and len(data_signals) > 0:
                            # æ£€æŸ¥ç¬¬ä¸€ä¸ªå…ƒç´ çš„ç»“æ„
                            if isinstance(data_signals[0], dict):
                                data_signals_df = pd.DataFrame(data_signals)
                            else:
                                # å¦‚æœä¸æ˜¯å­—å…¸åˆ—è¡¨ï¼Œåˆ›å»ºç®€å•çš„DataFrame
                                data_signals_df = pd.DataFrame({'ä¿¡å·': data_signals})
                        else:
                            data_signals_df = pd.DataFrame({'æç¤º': ['æ— æ•°æ®ä¿¡å·']})
                        data_signals_df.to_excel(writer, sheet_name='æ•°æ®ä¿¡å·', index=False)
                    else:
                        # åˆ›å»ºç©ºçš„æ•°æ®ä¿¡å·è¡¨
                        empty_df = pd.DataFrame({'æç¤º': ['æ— æ•°æ®ä¿¡å·']})
                        empty_df.to_excel(writer, sheet_name='æ•°æ®ä¿¡å·', index=False)
                else:
                    # åˆ›å»ºç©ºçš„æ•°æ®ä¿¡å·è¡¨
                    empty_df = pd.DataFrame({'æç¤º': ['æ— æ•°æ®ä¿¡å·']})
                    empty_df.to_excel(writer, sheet_name='æ•°æ®ä¿¡å·', index=False)
                
                # 5.3 å¯¼å‡ºevent_signalsï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if 'data' in data_only_result and 'event_signals' in data_only_result['data']:
                    event_signals = data_only_result['data']['event_signals']
                    if event_signals:
                        print(f"  - å¯¼å‡ºäº‹ä»¶ä¿¡å· ({len(event_signals)}æ¡)...")
                        if isinstance(event_signals, list) and len(event_signals) > 0:
                            if isinstance(event_signals[0], dict):
                                event_signals_df = pd.DataFrame(event_signals)
                            else:
                                event_signals_df = pd.DataFrame({'ä¿¡å·': event_signals})
                        else:
                            event_signals_df = pd.DataFrame({'æç¤º': ['æ— äº‹ä»¶ä¿¡å·']})
                        event_signals_df.to_excel(writer, sheet_name='äº‹ä»¶ä¿¡å·', index=False)
                    else:
                        # åˆ›å»ºç©ºçš„äº‹ä»¶ä¿¡å·è¡¨
                        empty_df = pd.DataFrame({'æç¤º': ['æ— äº‹ä»¶ä¿¡å·']})
                        empty_df.to_excel(writer, sheet_name='äº‹ä»¶ä¿¡å·', index=False)
                else:
                    # åˆ›å»ºç©ºçš„äº‹ä»¶ä¿¡å·è¡¨
                    empty_df = pd.DataFrame({'æç¤º': ['æ— äº‹ä»¶ä¿¡å·']})
                    empty_df.to_excel(writer, sheet_name='äº‹ä»¶ä¿¡å·', index=False)
                
                # 5.4 å¯¼å‡ºunified_signals
                if 'data' in data_only_result and 'unified_signals' in data_only_result['data']:
                    unified_signals = data_only_result['data']['unified_signals']
                    if unified_signals:
                        print(f"  - å¯¼å‡ºç»Ÿä¸€ä¿¡å· ({len(unified_signals)}æ¡)...")
                        try:
                            if isinstance(unified_signals, dict):
                                # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•è½¬æ¢ä¸ºDataFrame
                                if all(isinstance(v, (list, tuple)) and len(v) == len(list(unified_signals.values())[0]) for v in unified_signals.values()):
                                    # æ‰€æœ‰å€¼éƒ½æ˜¯ç›¸åŒé•¿åº¦çš„åˆ—è¡¨/å…ƒç»„
                                    unified_df = pd.DataFrame(unified_signals)
                                else:
                                    # å€¼é•¿åº¦ä¸åŒæˆ–åŒ…å«æ ‡é‡ï¼Œè½¬æ¢ä¸ºé”®å€¼å¯¹æ ¼å¼
                                    unified_df = pd.DataFrame([
                                        {'é”®': k, 'å€¼': str(v)} for k, v in unified_signals.items()
                                    ])
                            elif isinstance(unified_signals, list) and len(unified_signals) > 0:
                                if isinstance(unified_signals[0], dict):
                                    unified_df = pd.DataFrame(unified_signals)
                                else:
                                    unified_df = pd.DataFrame({'ä¿¡å·': unified_signals})
                            else:
                                unified_df = pd.DataFrame({'æç¤º': ['æ— ç»Ÿä¸€ä¿¡å·']})
                        except Exception as e:
                            print(f"    è­¦å‘Šï¼šç»Ÿä¸€ä¿¡å·DataFrameåˆ›å»ºå¤±è´¥: {e}")
                            # åˆ›å»ºè°ƒè¯•ä¿¡æ¯è¡¨
                            unified_df = pd.DataFrame({
                                'è°ƒè¯•ä¿¡æ¯': [f'ç»Ÿä¸€ä¿¡å·ç±»å‹: {type(unified_signals)}', 
                                           f'ç»Ÿä¸€ä¿¡å·å†…å®¹: {str(unified_signals)[:200]}...']
                            })
                        unified_df.to_excel(writer, sheet_name='ç»Ÿä¸€ä¿¡å·', index=False)
                    else:
                        # åˆ›å»ºç©ºçš„ç»Ÿä¸€ä¿¡å·è¡¨
                        empty_df = pd.DataFrame({'æç¤º': ['æ— ç»Ÿä¸€ä¿¡å·']})
                        empty_df.to_excel(writer, sheet_name='ç»Ÿä¸€ä¿¡å·', index=False)
                else:
                    # åˆ›å»ºç©ºçš„ç»Ÿä¸€ä¿¡å·è¡¨
                    empty_df = pd.DataFrame({'æç¤º': ['æ— ç»Ÿä¸€ä¿¡å·']})
                    empty_df.to_excel(writer, sheet_name='ç»Ÿä¸€ä¿¡å·', index=False)
                
                # 5.5 å¯¼å‡ºæ±‡æ€»ä¿¡æ¯
                summary_data = {
                    'é¡¹ç›®': ['è‚¡ç¥¨ä»£ç ', 'æ•°æ®æ—¶é—´èŒƒå›´', 'è‚¡ç¥¨æ•°æ®è¡Œæ•°', 'æ¨¡æ‹Ÿäº‹ä»¶æ•°é‡', 
                            'æ•°æ®ä¿¡å·æ•°é‡', 'äº‹ä»¶ä¿¡å·æ•°é‡', 'ç»Ÿä¸€ä¿¡å·æ•°é‡', 'å¯¼å‡ºæ—¶é—´'],
                    'å€¼': [
                        '000001.SH',
                        f"{df['æ—¥æœŸ'].min()} ~ {df['æ—¥æœŸ'].max()}",
                        len(df),
                        len(events_data),
                        data_only_result.get('data', {}).get('data_signals_count', 0),
                        data_only_result.get('data', {}).get('event_signals_count', 0),
                        data_only_result.get('data', {}).get('total_signals', 0),
                        timestamp
                    ]
                }
                summary_df = pd.DataFrame(summary_data)
                summary_df.to_excel(writer, sheet_name='æ±‡æ€»ä¿¡æ¯', index=False)
                
            print(f"âœ“ Excelæ–‡ä»¶å·²ä¿å­˜: {excel_file}")
            print(f"  åŒ…å«å·¥ä½œè¡¨: è‚¡ç¥¨å†å²æ•°æ®, æ•°æ®ä¿¡å·, äº‹ä»¶ä¿¡å·, ç»Ÿä¸€ä¿¡å·, æ±‡æ€»ä¿¡æ¯")
            
        except Exception as e:
            print(f"âŒ Excelå¯¼å‡ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        print("\n=== ç»Ÿä¸€ä¿¡å·ç”Ÿæˆå™¨è°ƒè¯•å®Œæˆ ===")
        
    except Exception as e:
        logger.error(f"ç»Ÿä¸€ä¿¡å·è°ƒè¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_unified_signals()
    # debug_basic_strategy_flow()